# -*- coding: utf-8 -*-
"""IE 7374 PROJECT FINAL VERSION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16gEvfrk3d0pmvIQUCpJ6s8ciXDwjLFIU
"""

!pip install plotly==5.5.0

import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from plotly.subplots import make_subplots
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import os
import random
import h5py
import tensorflow as tf
from tensorflow.python.framework import ops
import scikitplot as skplt
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from imblearn import over_sampling
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.feature_selection import SelectFromModel
from sklearn.feature_selection import RFECV
from scipy.optimize import Bounds
from scipy import optimize
from sklearn import datasets
from sklearn import svm
import time
import random
np.random.seed(1)

"""# I. Data Collection and Processing"""

#from google.colab import files
#file = files.upload()  #upload file into google colab session
df = pd.read_csv("bank-additional-full.csv",sep=';') 
df_origin = df.copy()
df.head()

"""#### 1. Remove all records with data of "Unknown"
"""

df.isnull().sum()

# drop missing value
df = df.replace('unknown', np.nan)
df_dropna = df.dropna()
df = df.dropna()

df.head()

"""### Description of predictors
##### Input variables:
##### BANK client data:
1. age (numeric)
2. job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')
3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)
4. education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')
5. default: has credit in default? (categorical: 'no','yes','unknown')
6. housing: has housing loan? (categorical: 'no','yes','unknown')
7. loan: has personal loan? (categorical: 'no','yes','unknown')

##### RALATED with the last contact of the current campaign:
8. contact: contact communication type (categorical: 'cellular','telephone')
9. month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')
10. day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')
11. duration: last contact duration, in seconds (numeric). Important note: **this attribute highly affects the output target**  (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.

##### OTHER attributes:
12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)
14. previous: number of contacts performed before this campaign and for this client (numeric)
15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')

##### SOCIAL and economic context attributes
16. emp.var.rate: employment variation rate - quarterly indicator (numeric)
17. cons.price.idx: consumer price index - monthly indicator (numeric)
18. cons.conf.idx: consumer confidence index - monthly indicator (numeric)
19. euribor3m: euribor 3 month rate - daily indicator (numeric)
20. nr.employed: number of employees - quarterly indicator (numeric)

##### OUTPUT variable (desired target):
21 - y - has the client subscribed a term deposit? (binary: 'yes','no')

**NOTE**: Above is the data encoding part. If you want to check the orignial dataframe without cleaning, call "df_origin", otherwise, keep using "df".

# II. Exploration and Visulization

### 1. Checking class
"""

plt.figure(figsize=(6,6))
plt.pie(df['y'].value_counts().values,labels=['Not subscribe', 'Scbscribe'],autopct='%1.2f%%',explode=(0, 0.1))
plt.title('Proportion of Customer Subscription',color='black',fontsize=15)
plt.legend(labels = ['Not subscribe', 'Scbscribe'], loc = "upper right")
plt.show()

"""### 2. Categorical predictors"""

fig, axarr = plt.subplots(2, 5, figsize=(20, 10))

sns.countplot('job', hue = 'y', data = df_dropna, ax = axarr[0][0])
sns.countplot('marital', hue = 'y', data = df_dropna, ax = axarr[0][1])
sns.countplot('education', hue = 'y', data = df_dropna, ax = axarr[0][2])
sns.countplot('default', hue = 'y', data = df_dropna, ax = axarr[0][3])
sns.countplot('housing', hue = 'y', data = df_dropna, ax = axarr[0][4])
sns.countplot('loan', hue = 'y', data = df_dropna, ax = axarr[1][0])
sns.countplot('contact', hue = 'y', data = df_dropna, ax = axarr[1][1])
sns.countplot('month', hue = 'y', data = df_dropna, ax = axarr[1][2])
sns.countplot('day_of_week', hue = 'y', data = df_dropna, ax = axarr[1][3])
sns.countplot('poutcome', hue = 'y', data = df_dropna, ax = axarr[1][4])

"""### 3. Numeric predictors"""

col = ['duration', 'age', 'campaign', 'pdays', 'previous', 'emp.var.rate','cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']
df[col].head()

fig = make_subplots(
    rows=4, cols=3, subplot_titles=[t for t in col]
)
for i in range(10):
    for p in px.box(df, x="y", y=df[col[i]], color="y").data:
        fig.add_trace(p, row=(i//3)+1, col=(i%3)+1)
fig.update_layout(height=900, width=1000, margin={"l": 10, "r": 10, "t": 30, "b": 10}).update_traces(showlegend=False)
fig.show()

px.box(df, x="y", y='duration', color="y")

fig = px.histogram(df, x="age", color="y", marginal="box")
fig.show()

fig = px.histogram(df, x="campaign", color="y", marginal="box")
fig.show()

fig = px.histogram(df, x="pdays", color="y", marginal="box")
fig.show()

fig = px.histogram(df, x="previous", color="y", marginal="box")
fig.show()

fig = px.histogram(df, x="emp.var.rate", color="y", marginal="box")
fig.show()

fig = px.histogram(df, x="cons.price.idx", color="y", marginal="box")
fig.show()

fig = px.histogram(df, x="cons.conf.idx", color="y", marginal="box")
fig.show()

fig = px.histogram(df, x="euribor3m", color="y", marginal="box")
fig.show()

fig = px.histogram(df, x="nr.employed", color="y", marginal="box")
fig.show()

cor = df[col].corr()
fig = px.imshow(cor, aspect="auto", color_continuous_scale='icefire', text_auto=True)
fig.show()

"""### 4. Statistical Testing (Chi-Square Test/Point Biserial)"""

cate_col = ['job', 'marital', 'education', 'default', 'housing','loan', 'contact', 'month', 'day_of_week','poutcome']
num_col = ['age', 'campaign', 'duration', 'pdays', 'previous', 'emp.var.rate','cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']

df_dropna['y'] = df_dropna['y'].replace({'yes': 1, 'no':0})

# pip install scipy
from scipy.stats import chi2_contingency
alpha = .05
dependent_col = []
m = 0
for i in range(len(cate_col)):
    data_crosstab = pd.crosstab(df_dropna[cate_col[i]],df_dropna['y'])
    print(data_crosstab)
    stat, p, dof, expected = chi2_contingency(data_crosstab)   
    if p <= alpha:
        print('Categorical variable',cate_col[i], 'and response variable are dependent (reject H0)')
        dependent_col.append(cate_col[i])
        m += 1
    else:
        print('Categorical variable',cate_col[i], 'and response variable are independent (H0 holds true)')
    print("P value is",str(p))
    print("")
print("")
print("There are", m, "categorical variables are dependent with response:")
for var in dependent_col:
  print(var)

from scipy.stats import pointbiserialr
response_var = df_dropna['y']
for i in range(len(num_col)):
  pbc = pointbiserialr(response_var,df_dropna[num_col[i]])
  print("Applying Point Biserial Correlation between response variable with",num_col[i])
  print(pbc)
  print("")

"""# III. Feature Selection

## III-1. PCA score on social and economic context attributes

**Explaination for III-1:** Since we found that the correlation coefficients between each two of social and economics indexes are high, we thought there must be a linear subspace for these numeric variables. Below is the code of Principal Component Analysis for 5 variables:

1. emp.var.rate: employment variation rate - quarterly indicator (numeric)
2. cons.price.idx: consumer price index - monthly indicator (numeric)
3. cons.conf.idx: consumer confidence index - monthly indicator (numeric)
4. euribor3m: euribor 3 month rate - daily indicator (numeric)
5. nr.employed: number of employees - quarterly indicator (numeric)
"""

from numpy import linalg 
df_econ = df[['emp.var.rate', 'cons.price.idx','cons.conf.idx','euribor3m','nr.employed']]

df_econ_mean = np.mean(df_econ,axis = 0)
df_econ = (df_econ - df_econ_mean) #centerlize

df_econ_covar = df_econ.T.dot(df_econ)
df_econ_eigvalue, df_econ_eigvector = np.linalg.eig(df_econ_covar) # Find eigen values/vectors
df_econ_PCA = df_econ.dot(df_econ_eigvector) # Calculate Z-score/projected coordinates on PCs
df_econ_PCA.columns = ['PC1','PC2','PC3','PC4','PC5']

# Preparing for plotting PCs' variations
df_PCA_var = pd.DataFrame(np.var(df_econ_PCA),columns = ['Variation'])
df_PCA_var = df_PCA_var.sort_values(by='Variation',ascending=False)
df_PCA_var['CumSum'] = df_PCA_var['Variation'].cumsum()/df_PCA_var['Variation'].sum()

df_PCA_var['Variation'].plot(kind='bar')
df_PCA_var['CumSum'].plot(secondary_y=True)
plt.title("Variation of 5 Principal Components")
plt.ylabel("Cumulative Sum of Variation")
plt.show()

"""**Note:** Below we used klearn Objection to check if we have correctly coding PCA."""

from sklearn.decomposition import PCA
pca=PCA()
pca.fit(df_econ)
pca.transform(df_econ)

# explained variance
print ("Explained Variance:")
print (pca.explained_variance_) 

# proportion variance
print ("Proportion Variance:")
print (pca.explained_variance_ratio_) 

# cummulative proportion of variance
print ("Cumulative Proportion of Variance:")
print (np.cumsum(pca.explained_variance_ratio_))

"""## III-2 Create New Variables

**Explanation for III-2:** We found there are 2 variables might be related with each other. 

Variable 'pdays' means number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted). However, most of them are 999, which means, these clients are not contacted from a previous campain. Thus, initially, we encoded these clients as pdays_cat = 0, as they did not have contact history, meanwhile others are encoded as 1. 

According to the distribution of these two groups colored by the response variable, we can see that previous customer has much more chance to subscribe the long term deposit.
"""

#change pdays to categorical
#999 -> 0
df['pdays_cat'] = 0
df.loc[df['pdays'] < 999, 'pdays_cat'] = 1

sns.countplot('pdays_cat', hue = 'y', data = df)
plt.title('Distribution of Successfully Contacted in 2 Groups')
plt.xlabel('Successfully Contacted')

px.histogram(df, x="pdays_cat", color="y", color_discrete_sequence=["steelblue","orange"], barmode = 'group')

"""**Explanation continued:** In addition to pdays, there is another variable for verifying whether the clients were contacted before, 'previous'. 'Previous' is the number of contacts performed before this campaign and for this client. 

Observing these two variables together, we found there is such a group of clients who were not contacted from previous campaigns but they actually had previous phone call records. In this condition, we thought they probably did not pick up the phone even though they might be on the contact list. Thus, we picked this group of clients out as group of 1 in the new variable called 'Contact Conditions'. Those ones successfully picked up the phone calls were encoded as 2, and those never received calls were encoded as 0.

Last, we dropped original variables 'pdays', 'previous', and 'pdays_cat', and only maintained the 'Contact Conditions' for later algorithms. 
"""

# Three Scenarios
# pdays == 999 & previous == 0 -> 1 never called before new clients
# pdays == 999 & previous >= 1 -> 0 called before but didnt went through
# pdays == 1 & previous >= 1   -> 2 old clients that made phone calls before

df['pdays_previous'] = 0
df.loc[(df['pdays_cat'] == 0) & (df['previous'] != 0), 'pdays_previous'] = 1 #打过电话的是1
df.loc[(df['pdays_cat'] != 0) & (df['previous'] > 0), 'pdays_previous'] = 2

px.histogram(df, x="pdays_previous", color="y", color_discrete_sequence=["steelblue","orange"], barmode = 'group')

sns.countplot('pdays_previous', hue = 'y', data = df)
plt.title('Distribution of 3 Contact Conditions in 2 Groups')
plt.xlabel('Contact Conditions')

"""## III-3. Drop Unnecessary Columns"""

df = df.drop(columns = ['default','housing','loan','pdays','previous','pdays_cat','emp.var.rate', 'cons.price.idx','cons.conf.idx','euribor3m','nr.employed'])

"""## III-4. Encoding Other Variables"""

# Encode job into numerical variables, numbered generally based on common sense of annual revenue 
df['job'] = df['job'].replace({'unemployed': 0, 
                               'student':1, 
                               'admin.':2,
                               'blue-collar':3,
                               'housemaid':4,
                               'services':5,
                               'retired':6,
                               'self-employed':7,
                               'technician':8,
                               'management':9,
                               'entrepreneur':10})

# Encode education into numerical variables, numbered generally based on common sense of education level 
df['education'] = df['education'].replace({'illiterate': 0, 
                                           'basic.4y':1, 
                                           'basic.6y':2,
                                           'basic.9y':3,
                                           'high.school':4,
                                           'professional.course':5,
                                           'university.degree':6})

df['month'] = df['month'].replace({'mar': 3, 
                                   'apr':4, 
                                   'may':5,
                                   'jun':6,
                                   'jul':7,
                                   'aug':8,
                                   'sep':9,
                                   'oct':10,
                                   'nov':11,
                                   'dec':12})

df['day_of_week'] = df['day_of_week'].replace({'mon': 1, 
                                               'tue':2, 
                                               'wed':3,
                                               'thu':4,
                                               'fri':5})

df['marital'] = df['marital'].replace({'single': 0, 
                                       'married':1, 
                                       'divorced':2})

df['contact'] = df['contact'].replace({'cellular': 1, 
                                       'telephone':0})

df['poutcome'] = df['poutcome'].replace({'nonexistent': 0,'failure':0,'success':1})

df.replace('yes',1,inplace=True)
df.replace('no',0,inplace=True)

# PCA score
df['Econ PC1'] = df_econ_PCA['PC1']

df_nb = df.copy() # store unscaled data for Naive Bayes

# except for nb
df = (df-df.min())/(df.max()-df.min()) #1
for column in df.columns:
  df[column] = df[column] / df[column].abs().max() #2

display(df) # check normalized data

"""## III-5. Random Forest for Profiling"""

y = df['y']
X = df.drop(columns='y')
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

sel = RandomForestClassifier(n_estimators = 100, random_state=0)
sel.fit(X_train, y_train)

df_feature = np.empty(shape=(len(X.columns),2),dtype='object')

for i in range(len(X.columns)):
  df_feature[i,0] = X.columns[i]
  df_feature[i,1] = sel.feature_importances_[i]

df_feature = pd.DataFrame(df_feature)
df_feature.columns = ['Feature','Importance']
df_feature.sort_values('Importance',ascending = False)

plt.figure(figsize=(8,10))
# make barplot and sort bars
sns.barplot(x='Importance',
            y="Feature", 
            data=df_feature, 
            orient = 'h',
            order=df_feature.sort_values('Importance',ascending = False).Feature)
# set labels
plt.xlabel("Importance")
plt.title("Feature Importance By Random Forest", size=18)
plt.xticks(rotation=45)
plt.tight_layout()

"""# IV. Modeling

## IV-1. Logistic Regression

### A. Choose X and y
"""

X = df.loc[:,['age', 'job', 'marital', 'education', 'contact', 'month', 'day_of_week',
       'duration', 'campaign', 'poutcome', 'pdays_previous', 'Econ PC1' ]]
y = df['y']

X_train, X_val, y_train, y_val = train_test_split(X, 
                                                  y, 
                                                  test_size=0.2, 
                                                  random_state=1)

"""### B. Algorithm Coding"""

class LogisticRegression():
    
    def __init__(self, X, y,learningRate, tolerance, maxIteration,lamda,cutoff) -> None:
        self.X = X
        self.y = y
        self.learningRate = learningRate
        self.tolerance = tolerance
        self.maxIteration = maxIteration
        self.lamda = lamda # adding a penalize parameter
        self.cutoff = cutoff #adding a cutoff parameter
        
    def addX0(self,X):
        return np.column_stack([np.ones([X.shape[0]]),X])
    
    def sigmoid(self,z):      
        sig = 1/(1 + np.exp(-z))
        return sig
    
    def costFunction(self,X,y):       
        pred_ = np.log(np.ones(X.shape[0]) + np.exp(X.dot(self.w))) - X.dot(self.w)*y 
        cost = pred_.sum() + (self.lamda * (np.linalg.norm(self.w,2))**2)/2
        return cost
    
    def gradient(self,X,y):
        sig = self.sigmoid(X.dot(self.w))        
        grad = (sig - y).dot(X) + self.lamda * (np.linalg.norm(self.w,2))
        return grad 
    
    def gradientDescent(self,X,y):
        errors = []
        last = float('inf')       
        for i in tqdm(range(self.maxIteration)):
            self.w = self.w - self.learningRate * self.gradient(X,y)
            curr = self.costFunction(X,y)            
            diff = last - curr
            last = curr           
            errors.append(curr)            
            if diff < self.tolerance:
                print('Model stopped')
                break          
        self.plot_cost(errors)
        return
               
    def predict (self,X):
        self.proba = self.sigmoid(X.dot(self.w))
        a=[]
        for i in range(0,len(self.proba)):
          if self.proba[i] > self.cutoff:
            a.append(1)
          else:
            a.append(0)
        return np.array(a)
    
    def evaluate_1(self,y,y_hat):
        y = (y == 1)
        y_hat = (y_hat==1)        
        precision = (y & y_hat).sum() / y_hat.sum()
        recall = (y & y_hat).sum()/y.sum()
        fScore = 2*(precision*recall)/(precision+recall)       
        return fScore, recall, precision
    
    def evaluate_0(self,y,y_hat):
        y = (y == 0)
        y_hat = (y_hat==0)        
        precision = (y & y_hat).sum() / y_hat.sum()
        recall = (y & y_hat).sum()/y.sum()
        fScore = 2*(precision*recall)/(precision+recall)       
        return fScore, recall, precision

    def run_model(self):
        # Find the expected w values
        X = self.X
        y = self.y        
        self.w = np.ones(self.X.shape[1], dtype=np.float64) * 0
        # self.w = np.ones(self.X_train.shape[1],dtype=np.float64) *0
        self.gradientDescent(X, y)
        
        print(self.w)
        
        y_hat_train = self.predict(X)

        fScore1,recall1,precision1 = self.evaluate_1(y, y_hat_train)
        print('Evaluation of class 1:')
        print('F1_score is:', fScore1)
        print('Precision is:' , precision1)
        print('Recall is:', recall1)

        fScore0,recall0,precision0 = self.evaluate_0(y, y_hat_train)
        print('Evaluation of class 0:')
        print('F1_score is:', fScore0)
        print('Precision is:' , precision0)
        print('Recall is:', recall0)
        
    def test_evaluate(self,X,y):
        y_hat_test = self.predict(X)
        fScore1,recall1,precision1 = self.evaluate_1(y, y_hat_test)
        print('Evaluation of class 1:')
        print('F1_score is:', fScore1)
        print('Precision is:' , precision1)
        print('Recall is:', recall1)

        fScore0,recall0,precision0 = self.evaluate_0(y, y_hat_test)
        print('Evaluation of class 0:')
        print('F1_score is:', fScore0)
        print('Precision is:' , precision0)
        print('Recall is:', recall0)
        
########################## Plotting###################
      
    def plot_cost(self, cost_sequence):
        # Data for plotting
        s = np.array(cost_sequence)
        t = np.arange(s.size)

        fig, ax = plt.subplots()
        ax.plot(t, s)

        ax.set(xlabel='iterations', ylabel='cost',
               title='cost trend')
        ax.grid()
        plt.show()

"""### C. Training and Testing with Original Dataset"""

lr_origin = LogisticRegression(X_train.values, 
                        y_train.values,
                        tolerance=0.0000005,
                        maxIteration=50000,
                        learningRate = 0.000001,
                        lamda = 0.05,
                        cutoff = 0.5)

lr_origin.run_model()

lr_origin.test_evaluate(X_val.values,y_val.values)

skplt.metrics.plot_confusion_matrix(y_val, 
                                    lr_origin.predict(X_val.values),
                                    normalize=True,
                                    title="Confusion Matrix for Logistic Regression (Non-Oversampling)",
                                    figsize=(10, 8))

"""### D. Oversampling"""

ros = RandomOverSampler(random_state=42)
X_osa, y_osa = ros.fit_resample(X_train, y_train)

lr_osa = LogisticRegression(X_osa.values, 
                        y_osa.values,
                        tolerance=0.0000005,
                        maxIteration=50000,
                        learningRate = 0.000001,
                        lamda = 0.05,
                        cutoff = 0.5)

lr_osa.run_model()

lr_osa.test_evaluate(X_val.values,y_val.values)

skplt.metrics.plot_confusion_matrix(y_val, 
                                    lr_osa.predict(X_val.values),
                                    normalize=True,
                                    title="Confusion Matrix for Logistic Regression (Oversampling)",
                                    figsize=(10, 8))

# cutoff value tuning
lr_osa.predict(X_osa.values)
cutoff=[]
recall_1=[]
acc_lr=[]
for j in np.arange(0.4,0.6,0.01):
  cutoff.append(j)
  a=[]
  for i in range(0,len(lr_osa.proba)):
    if lr_osa.proba[i]>j:
      a.append(1)
    else:
      a.append(0)
  logit_result = pd.DataFrame({'actual':y_osa,
                               'y_new':a})
  
  TP = ((logit_result.y_new == 1) & (y_osa == 1)).sum()
  FN = ((logit_result.y_new == 0) & (y_osa == 1)).sum()
  TN = ((logit_result.y_new == 0) & (y_osa == 0)).sum()
  FP = ((logit_result.y_new == 1) & (y_osa == 0)).sum()

  acc = (TP + TN) / (TP + TN + FP + FN)
  recall = TP / (TP + FN)
  recall_1.append(recall)
  acc_lr.append(acc)
cutofftune = pd.DataFrame({'cutoff':cutoff,
                           'recall_1':recall_1,
                           'accuracy':acc_lr})
plt.plot(cutofftune['cutoff'],cutofftune['accuracy'],marker='o', label='accuracy')
plt.plot(cutofftune['cutoff'],cutofftune['recall_1'],marker='*', label='recall_1')
plt.legend()
plt.xlabel("Cut-off") 
plt.ylabel("Probability") 
plt.title("Cut-off Tuning") 
plt.show()

lr_c = LogisticRegression(X_osa.values, 
                        y_osa.values,
                        tolerance=0.0000005,
                        maxIteration=50000,
                        learningRate = 0.000001,
                        lamda = 0.05,
                        cutoff = 0.49)

lr_c.run_model()

lr_c.test_evaluate(X_val.values,y_val.values)

skplt.metrics.plot_confusion_matrix(y_val, 
                                    lr_osa.predict(X_val.values),
                                    normalize=True,
                                    title="Confusion Matrix for Logistic Regression (Cut-off tuning)",
                                    figsize=(10, 8))

"""## IV-2. NB"""

tmp_df = df.copy()

df = df_nb.copy()

"""### A. Algorithm Coding"""

class Discrete_NaiveBayes:
    def __init__(self, X, y, laplacesmoothing = False, oversample = False, undersample = False) -> None:
        self.X = X
        self.y = y
        self.laplacesmoothing = laplacesmoothing
        self.oversample = oversample
        self.undersample = undersample
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size = 0.3, 
                                                                                random_state = 0)
        if(self.oversample):
          ros = RandomOverSampler(random_state=42)
          self.X_train, self.y_train = ros.fit_resample(self.X_train, self.y_train)

        if(self.undersample):
          rus = RandomUnderSampler(random_state=42, sampling_strategy='majority')
          self.X_train, self.y_train = rus.fit_resample(self.X_train, self.y_train)
        

    def probability_discrete_y0(self, X, proba):
        result = self.prior_y0
        
        for i in proba['y0'].keys():
          result *= proba['y0'][i][X[i]]
        return result
  
    def probability_discrete_y1(self, X, proba):
        result = self.prior_y1
        
        for i in proba['y1'].keys():
          result *= proba['y1'][i][X[i]]
        return result
             
    def fit_discrete(self):
      # divide into two target value
        self.proba = {}
        self.proba['y1'] = {}
        self.proba['y0'] = {}
        self.X0_train = self.X_train[self.y_train == 0]#target = 0的x_train
        self.X1_train = self.X_train[self.y_train == 1]
        
      # calculate prior of two target
        self.prior_y0 = len(self.X0_train) / len(self.X_train)
        self.prior_y1 = len(self.X1_train) / len(self.X_train)

        if (not self.laplacesmoothing):
        # calculate the P(x|y==0)
          for i in X.columns:
            self.proba['y0'][i] = {}
            for j in X[i].unique():
              self.proba['y0'][i][j] = {}
              self.proba['y0'][i][j] = len(self.X0_train[self.X0_train[i]==j]) / len(self.X0_train)
        # calculate the P(x|y==1)
          for i in X.columns:
            self.proba['y1'][i] = {}
            for j in X[i].unique():
              self.proba['y1'][i][j] = {}
              self.proba['y1'][i][j] = len(self.X1_train[self.X1_train[i]==j]) / len(self.X1_train)

        elif (self.laplacesmoothing):
          self.laplace = {}
          for i in X.columns:
            self.laplace[i] = len(np.unique(self.X[i]))
          t = random.randint(1, 10)
          # calculate the P(x|y==0)
          for i in X.columns:
            self.proba['y0'][i] = {}
            for j in X[i].unique():
              self.proba['y0'][i][j] = len(self.X0_train[self.X0_train[i]==j]) / (len(self.X0_train) + self.laplace[i] * t)
          # calculate the P(x|y==1)
          for i in X.columns:
            self.proba['y1'][i] = {}
            for j in X[i].unique():
              self.proba['y1'][i][j] = len(self.X1_train[self.X1_train[i]==j]) / (len(self.X1_train) + self.laplace[i] * t)

    def predict(self):
        count = 0
        for i in range(0, self.X_test.shape[0]):
            py0 = self.probability_discrete_y0(self.X_test.iloc[i], self.proba)
            py1 = self.probability_discrete_y1(self.X_test.iloc[i], self.proba)
                                                                                
            if np.argmax([py0*100,py1*100]) != self.y_test.iloc[i]:
                count +=1
        print(count)
        return count
      
    def predict_(self, X):
        result = pd.Series()
        for i in range(0, X.shape[0]):
          py0 = self.probability_discrete_y0(X.iloc[i], self.proba)
          py1 = self.probability_discrete_y1(X.iloc[i], self.proba)
          result = result.append(pd.Series(np.argmax([py0*100,py1*100])))
        return result

"""### B. Support Functions"""

# Try to make each bins have the same amount of data
def bin(df, predictor, numofbin): 
  percentile = 1/numofbin
  for i in range(1, numofbin+1):
    df.loc[(df[predictor] > (df[predictor].quantile(q = (i-1)*percentile))) & (df[predictor] <= (df[predictor].quantile(q = i*percentile)))  , predictor] = i
  df[~df[predictor].isin(range(1, numofbin+1))] = 1

# Plot the percentage of Class 1 in each bin
def plot_percentage(df, predictor): 
  percent = pd.DataFrame(df.groupby(predictor)['y'].value_counts())
  x = []
  y = []
  for i in sorted(df[predictor].unique()):
    x.append(i)
    if (1 in (percent.loc[i].index)):
      y.append((percent.loc[(i,1)] / sum(percent.loc[(i)].values)).values[0])
    else:
      y.append(0)

  tmp_df = pd.DataFrame(dict(
    x = x,
    y = y))
  fig = px.line(tmp_df, x="x", y="y", title=predictor)
  fig.show()

fig = px.histogram(df, x="Econ PC1", color="y", marginal="box")
fig.show()

fig = px.histogram(df, x="Econ PC1")
fig.show()

plot_percentage(df, 'duration')

"""### C. Find the optimal number of bins for each predictors"""

df = df_nb.copy()
opt_bin = []
opt_error = np.inf
for i in range(2, 4):
  bin(df, 'age', i)
  for j in range(2, 4):
    bin(df, 'campaign', j)
    for u in range(5, 11):
      bin(df, 'duration', u)
      for v in range(5, 11):
        bin(df, 'Econ PC1', v)
        print(i, j, u, v)
        X = df.loc[:,[
                'age',
                'job',
                'marital',
                'education',
                'contact',
                'month',
                'day_of_week',
                'duration',
                'campaign',
                'poutcome',
                'pdays_previous',
                'Econ PC1'
                ]]
        y = df['y']
        nb_discrete = Discrete_NaiveBayes(X, y, laplacesmoothing = True)
        nb_discrete.fit_discrete()
        error = nb_discrete.predict()
        if(error < opt_error):
          opt_bin = [i, j, u, v]
          opt_error = error
        df = df_nb.copy()

opt_bin, opt_error

bin(df, 'age', 2)
bin(df, 'campaign', 2)
bin(df, 'duration', 6)
bin(df, 'Econ PC1', 10)

"""### D. Choose X and y"""

X = df.loc[:,[
              'age',
              'job',
              'marital',
              'education',
              'contact',
              'month',
              'day_of_week',
              'duration',
              'campaign',
              'poutcome',
              'pdays_previous',
              'Econ PC1'
              ]]
y = df['y']

nb_discrete = Discrete_NaiveBayes(X, y, laplacesmoothing = True, oversample = False)
nb_discrete.fit_discrete()

skplt.metrics.plot_confusion_matrix(nb_discrete.y_test, 
                                    nb_discrete.predict_(nb_discrete.X_test),
                                    normalize=True,
                                    title="Confusion Matrix for Naive Bayes",
                                    figsize=(10, 8))

print(classification_report(nb_discrete.y_test, nb_discrete.predict_(nb_discrete.X_test)))

df = tmp_df.copy()

"""## IV-3. SVM

### A. Choose X and y
"""

X = df.loc[:,['age', 'job', 'marital', 'education', 'contact', 'month', 'day_of_week',
       'duration', 'campaign', 'poutcome', 'pdays_previous', 'Econ PC1' ]]
y = df['y']

X_train, X_val, y_train, y_val = train_test_split(X, 
                                                  y, 
                                                  test_size=0.2, 
                                                  random_state=1)

ros = RandomUnderSampler(random_state=42)
X_usa, y_usa = ros.fit_resample(X_train, y_train)

"""### B.Soft Margin SVM - Hinge Loss"""

#HardMargin SVM
class HardMarginSVM:
    def __init__(self, learning_rate = 0.0001, lambda_param = 0.001, n_iters = 1000):
        self.learning_rate = learning_rate 
        self.lambda_param = lambda_param
        self.n_iters = n_iters
        
        
    def fit(self, X, y):
        n_samples, n_features = X.shape[0],X.shape[1]
        X = X.values
        y_ = np.where(y <= 0, -1, 1)
        self.w = np.zeros(n_features)
        self.b = 0
        

        for _ in range(self.n_iters):
            for idx, x_i in enumerate(X):
                condition = y_[idx]*(np.dot(x_i,self.w) + self.b) >= 1
                
                if condition:
                    self.w -= self.learning_rate * (2 * self.lambda_param * self.w)
                    
                else:
                    self.w -= self.learning_rate * (2 * self.lambda_param * self.w - np.dot(x_i,y_[idx]))
                    self.b -= self.learning_rate * -(y_[idx])
                    
    def predict(self, X):
        pred_ = np.dot(X, self.w) + self.b
        return np.sign(pred_)

# Commented out IPython magic to ensure Python compatibility.
clf = HardMarginSVM()
clf.fit(X_train,y_train)
print(clf.w, clf.b)
# %time

skplt.metrics.plot_confusion_matrix(y_val*2-1, 
                                    clf.predict(X_val.values),
                                    normalize=True,
                                    title="Confusion Matrix for SVM_hinge (Original Data)",
                                    figsize=(10, 8))

from sklearn.metrics import classification_report

print(classification_report(y_train*2-1, clf.predict(X_train.values)))

print(classification_report(y_val*2-1, clf.predict(X_val.values))) #算recall f1 precision

"""Undersampling"""

# Commented out IPython magic to ensure Python compatibility.
clf1 = HardMarginSVM()
clf1.fit(X_usa,y_usa)
print(clf1.w, clf1.b)
# %time

skplt.metrics.plot_confusion_matrix(y_val*2-1,
                                    clf1.predict(X_val.values),
                                    normalize=True,
                                    title="Confusion Matrix for SVM_hinge (Undersampling)",
                                    figsize=(10, 8))

print(classification_report(y_train*2-1, clf1.predict(X_train.values)))

print(classification_report(y_val*2-1, clf1.predict(X_val.values)))

"""### C. Soft Margin SVM - Dual Problem Optimization"""

class SoftMarginSVM:
    def __init__(self,C):
        self.C = C
        
    def fit(self,X,y):
        N = len(y)
        
        Xy = X*y[:,np.newaxis]
        
        GramXy = np.matmul(Xy, Xy.T)
        
        def ld0(G, alpha):
            return alpha.sum() - 0.5*alpha.dot(alpha.dot(G))
        
        def derivativeLd0 (G, alpha):
            return np.ones_like(alpha) - alpha.dot(G)
        
        alpha = np.ones(N)
        bounds_alpha = Bounds(np.zeros(N),np.full(N,self.C))
        
        #A = np.vstack((-np.eye(N), np.eye(N)))
        
        constraints = ({'type':'eq',
                       'fun':lambda a: np.dot(a,y),
                       'jac':lambda a: y})
        
        optRes = optimize.minimize(fun = lambda a : -ld0(GramXy,a),
                                   x0 = alpha,
                                   jac = lambda a: -derivativeLd0(GramXy,a),
                                   constraints = constraints,
                                   bounds = bounds_alpha,
                                   method = 'SLSQP')
        self.alpha = optRes.x
        
        self.w = np.sum((self.alpha[:,np.newaxis]*Xy), axis=0)
        
        epsilon = 1e-4
        
        self.supportVectors = X[self.alpha > epsilon]
        self.supportLabels = y[self.alpha > epsilon]
        
        
        self.b = []
        for i in range(len(self.supportVectors)):
            b_i = self.supportLabels[i] - np.matmul(self.supportVectors[i].T, self.w)
            self.b.append(b_i)
        self.intercept = sum(self.b)/len(self.b)
    
    def predict(self, X_val, X_train, y_train):        
        y = np.where(y_train <= 0, -1, 1)
        return np.sign(np.dot(X_val.values, self.w) + self.intercept)

svm_soft = SoftMarginSVM(C=20)
svm_soft.fit(X_usa.values,y_usa.values)

svm_soft_pred = np.sign(np.dot(X_val.values, svm_soft.w) + svm_soft.intercept)

print(classification_report(y_val*2-1, np.sign(np.dot(X_val.values, svm_soft.w) + svm_soft.intercept)))

skplt.metrics.plot_confusion_matrix(y_val*2-1, 
                                    svm_soft_pred,
                                    normalize=True,
                                    title="Confusion Matrix for Soft Margin SVM",
                                    figsize=(10, 8))

"""### D. SMO Algorithm (Kernel)"""

from sklearn.utils import shuffle
X_usa, y_usa = shuffle(X_usa, y_usa, random_state=0)

class SMO_kernel:
    
    def __init__(self,C,tolerance,max_iter,theta):
        self.C = C
        self.tolerance = tolerance
        self.max_iter = max_iter
        self.theta = theta #Rbf Kernel param      
        
    def Kernel(self,x,z):
        return np.exp(((x-z).T.dot(x-z))/(-1*self.theta**2))
    
    def GramK(self,X):
        m = X.shape[0]
        K = np.zeros((m,m),dtype='float64')
        for i in range(m):
            for j in range(m):
                K[i,j] = self.Kernel(X[i,:],X[j,:])
        return K
                
    def L(self, alpha1, alpha2, y1, y2):
        if y1 != y2:
            return max(0, alpha2 - alpha1)
        else:
            return max(0, alpha1 + alpha2 - self.C)

    def H(self, alpha1, alpha2, y1, y2):
        if y1 != y2:
            return min(self.C, self.C - alpha1 + alpha2)
        else:
            return min(self.C, alpha1 + alpha2) 

    def clip(self,alpha2, H, L):
        if alpha2 > H:
            return H
        elif alpha2 < L:
            return L
        else:
            return alpha2

    def compute_b(self, b1, b2, alpha1, alpha2):
        if alpha1 > 0 and alpha1 < self.C:
            return b1
        elif alpha2 > 0 and alpha2 < self.C:
            return b2
        else:
            return (b1+ b2) / 2

    def fit(self,X,y):
        m = X.shape[0]    
        b = 0
        alpha = np.zeros(m)
        alphap = np.zeros(m)
        iter = 0
        #self.K = self.GramK(X)
        self.K = X

        while iter < self.max_iter:
            print('Starting Iteration: ', iter)
            num_changed_alphas = 0
            for i in tqdm(range(1, m)):                              
                E1 = (alpha * y).T.dot(self.K[:,i]) - y[i] + b
                
                yE = y[i] * E1
                    
                if (yE< (-1 * self.tolerance) and alpha[i] < self.C) or (yE > self.tolerance and alpha[i] > 0):
                    j = self.J(m, i)
                    
                    E2 = (alpha * y).T.dot(self.K[:,j]) - y[j] + b
                    
                    alphap[i], alphap[j] = alpha[i], alpha[j]
                    
                    L = self.L(alpha[i], alpha[j], y[i], y[j])

                    H = self.H(alpha[i], alpha[j], y[i], y[j])                
                    
                    if L == H:
                          continue
                            
                    eta = 2*self.K[i,j] - self.K[i,i] - self.K[j,j]
                    
                    if eta >= 0: 
                          continue
                    alpha[j] = alpha[j] - ((y[j] * (E1 - E2)) / eta)
                    
                    alpha[j] = self.clip(alpha[j], H, L)

                    if np.absolute(alpha[j] - alphap[j]) < 0.00005:
                          continue
                            
                    alpha[i] = alpha[i] + (y[i] * y[j]) * (alphap[j] - alpha[j])

                    b1 = b - E1 - y[i] * (alpha[i] - alphap[i]) * self.K[i,i] - y[j] * (alpha[j] - alphap[j]) * self.K[i,j]
                    #    b - E1 - y1 * (alpha1 - alpha1p) * self.Kernel(X1, X1) - y2 * (alpha2 - alpha2p) * self.Kernel(X1, X2) 
                    b2 = b - E2 - y[i] * (alpha[i] - alphap[i]) * self.K[i,j] - y[j] * (alpha[j] - alphap[j]) * self.K[j,j]
                    #    b - E2 - y1 * (alpha1 - alpha1p) * self.Kernel(X1, X2) - y2 * (alpha2 - alpha2p) * self.Kernel(X2, X2)
                    
                    b = self.compute_b(b1, b2, alpha[i], alpha[j])
                    
                    num_changed_alphas += 1

            if num_changed_alphas == 0:               
                iter += 1
            else:
                print('Resetting Iteration to 0')
                iter = 0 #different from pseudo code, before is 0

        return alpha, b

    def J(self, m, i):    
        random.seed(time.time())
        j = np.random.randint(0, m)
        while i == j:
            j = np.random.randint(0, m)
        return j


    def predict(self, alpha, b, X_val, X_train, y_train):        
        w = (alpha * y_train).T.dot(X_train)
        return np.sign(np.dot(X_val.values,w) + b)

def Kernel(x,z):
        return np.exp(((x-z).T.dot(x-z))/(-1*2**2))
    
    def GramK(X):
        m = X.shape[0]
        K = np.zeros((m,m),dtype='float64')
        for i in tqdm(range(m)):
            for j in range(m):
                K[i,j] = Kernel(X[i,:],X[j,:])
        return K

k = GramK(X_usa.values)

k

# # Origin Data
# svm_smo_1 = SMO_kernel(C=1, tolerance= 0.00005, max_iter = 100, theta=5)

# a1, b1 = svm_smo_1.fit(X_train.values,y_train.values)

# skplt.metrics.plot_confusion_matrix(y_val*2-1, 
#                                     svm_smo_1.predict(a1,b1,X_val,X_train.values,(y_train*2-1))*2 -1,
#                                     normalize=True,
#                                     title="Confusion Matrix for SVM (Kernel,Original Dataset)",
#                                     figsize=(10, 8))

# print(classification_report(y_val*2-1, svm_smo_1.predict(a1,b1,X_val,X_train.values,y_train)))

# print(classification_report(y_train*2-1,svm_smo_1.predict(a1,b1,X_train,X_train.values,y_train)))

# Undersampling Data
svm_smo_2 = SMO_kernel(C=1, tolerance= 0.00005, max_iter = 100, theta=5)

a2, b2 = svm_smo_2.fit(k,(y_usa*2-1).values)

smo_pred = svm_smo_2.predict(a2, b2, X_val, X_usa, (y_usa*2-1))

skplt.metrics.plot_confusion_matrix(y_val*2-1, 
                                    smo_pred,
                                    normalize=True,
                                    title="Confusion Matrix for SVM (Kernel,Original Dataset)",
                                    figsize=(10, 8))

print(classification_report(y_val*2-1, smo_pred))

print(classification_report(y_train*2-1,svm_smo_2.predict(a2, b2, X_train, X_usa, (y_usa*2-1))))

"""## IV-4. NN

### A. Choose X and y
"""

X = df.loc[:,['age', 'job', 'marital', 'education', 'contact', 'month', 'day_of_week',
       'duration', 'campaign', 'poutcome', 'pdays_previous', 'Econ PC1' ]]
y = df['y']

X_train, X_val, y_train, y_val = train_test_split(X, 
                                                  y, 
                                                  test_size=0.2, 
                                                  random_state=1)

ros = RandomOverSampler(random_state=42)
X_osa, y_osa = ros.fit_resample(X_train, y_train)

y_osa = np.array(y_osa)
y_osa = y_osa[np.newaxis]
y_val = np.array(y_val)
y_val = y_val[np.newaxis]

"""### B. Algorithm coding"""

def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):
    """
    Creates a list of random minibatches from (X, Y)
    
    Arguments:
    X -- input data, of shape (input size, number of examples)
    Y -- true "label" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)
    mini_batch_size - size of the mini-batches, integer
    seed -- this is only for the purpose of grading, so that you're "random minibatches are the same as ours.
    
    Returns:
    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)
    """
    
    m = X.shape[1]                  # number of training examples
    mini_batches = []
    np.random.seed(seed)
    
    # Step 1: Shuffle (X, Y)
    permutation = list(np.random.permutation(m))
    #Y = np.array(Y)
    #Y = Y[np.newaxis]
    shuffled_X = X.iloc[:, permutation]
    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))

    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.
    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning
    for k in range(0, num_complete_minibatches):
        mini_batch_X = shuffled_X.iloc[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]
        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]
        mini_batch = (mini_batch_X, mini_batch_Y)
        mini_batches.append(mini_batch)
    
    # Handling the end case (last mini-batch < mini_batch_size)
    if m % mini_batch_size != 0:
        mini_batch_X = shuffled_X.iloc[:, num_complete_minibatches * mini_batch_size : m]
        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]
        mini_batch = (mini_batch_X, mini_batch_Y)
        mini_batches.append(mini_batch)
    
    return mini_batches

def initializer():
    initializer = tf.initializers.GlorotNormal(seed=1)            #input layer:12 nodes
    w1 = tf.Variable(initializer(shape = (6, 12)), name = 'w1') #hidden layer 1: 10 nodes
    w2 = tf.Variable(initializer(shape = (8, 6)), name = 'w2') #hidden layer 2: 8 nodes
    w3 = tf.Variable(initializer(shape = (1, 8)), name = 'w3') #output layer: 1 node
    
    b1 = tf.Variable(tf.zeros([6, 1]), name = 'b1')
    b2 = tf.Variable(tf.zeros([8, 1]), name = 'b2') 
    b3 = tf.Variable(tf.zeros([1, 1]), name = 'b3')
    
    parameters = {
        'w1':w1,
        'w2':w2,
        'w3':w3,
        'b1':b1,
        'b2':b2,
        'b3':b3
    }
    return parameters

def forwardPass(X, y ,parameters):
    z1 = tf.add(tf.matmul(parameters['w1'], X), parameters['b1'])
    o1 = tf.nn.relu(z1)
    
    z2 = tf.add(tf.matmul(parameters['w2'], o1), parameters['b2'])
    o2 = tf.nn.sigmoid(z2)
    
    z3 = tf.add(tf.matmul(parameters['w3'], o2), parameters['b3'])
    
    return z3

"""### C. 1st Define Cost Function"""

parameter_initializer = initializer()

def BinaryCostFunction(z3, y):
    logits = tf.sigmoid(tf.transpose(z3))
    #labels = tf.transpose(y)
    # regularization
    regularzation = 0.01*(1/(2 * y.shape[1]))*(tf.math.reduce_sum(tf.math.square(parameter_initializer['w1'].numpy())) + 
                          tf.math.reduce_sum(tf.math.square(parameter_initializer['w2'].numpy())) + 
                          tf.math.reduce_sum(tf.math.square(parameter_initializer['w3'].numpy())))
    cost = -tf.reduce_mean(y * tf.math.log(tf.clip_by_value(logits,1e-10,1.0))+(1-y) * tf.math.log(tf.clip_by_value(1-logits,1e-10,1.0))) + regularzation
    return cost

def gradient(inputs, targets, parameters):
    with tf.GradientTape() as tape:
        z3 = forwardPass(inputs, targets, parameters)
        # control the cost function
        loss_value = BinaryCostFunction(z3, targets) # 1st
        
    return [tape.gradient(loss_value, list(parameters.values())), loss_value]

# run 18 mins
optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001)

for epoch in range(100):
    minibatches = random_mini_batches(X_osa.T, y_osa, 32, seed = 1)
    
    for minibatch in minibatches:
        x = minibatch[0].astype(np.float32)
        y = minibatch[1].astype(np.float32)
        
        grads, loss_value = gradient(x, y, parameter_initializer)
        optimizer.apply_gradients(zip(grads, list(parameter_initializer.values())))

def evaluate_1(y,y_hat):
        y = (y == 1)
        y_hat = (y_hat==1)        
        precision = (y & y_hat).sum() / y_hat.sum()
        recall = (y & y_hat).sum()/y.sum()
        fScore = 2*(precision*recall)/(precision+recall)       
        return fScore, recall, precision
    
def evaluate_0(y,y_hat):
        y = (y == 0)
        y_hat = (y_hat==0)        
        precision = (y & y_hat).sum() / y_hat.sum()
        recall = (y & y_hat).sum()/y.sum()
        fScore = 2*(precision*recall)/(precision+recall)       
        return fScore, recall, precision

def EvaluatePerformance(X_train, y_train, X_val, y_val, parameters):
    # training set prediction
    predictproba_train = forwardPass(X_train.T, y_train, parameters)
    predict_train = np.round(tf.sigmoid(predictproba_train))
    fScore,recall,precision = evaluate_1(y_train, predict_train)
    print('Evaluation of traing set:')
    print('F1_score is:', fScore)
    print('Precision is:' , precision)
    print('Recall is:', recall)
    
    #validation set prediction
    predictproba_val = forwardPass(X_val.T, y_val, parameters)
    predict_val = np.round(tf.sigmoid(predictproba_val))
    fScore1,recall1,precision1 = evaluate_1(y_val, predict_val)
    print('Evaluation of validation set(class 1):')
    print('F1_score is:', fScore1)
    print('Precision is:' , precision1)
    print('Recall is:', recall1)
    fScore0,recall0,precision0 = evaluate_0(y_val, predict_val)
    print('Evaluation of validation set(class 0):')
    print('F1_score is:', fScore0)
    print('Precision is:' , precision0)
    print('Recall is:', recall0)
    
    # dimensionality reduction
    y_val=np.squeeze(y_val)
    predict_val = np.squeeze(predict_val)
    
    skplt.metrics.plot_confusion_matrix(y_val, 
                                        predict_val,
                                        normalize=True,
                                        title="Confusion Matrix for Logistic Regression (Oversampling)",
                                        figsize=(10, 8))

EvaluatePerformance(X_osa, y_osa, X_val, y_val, parameter_initializer)

"""### D. 2st sigmoid_cross_entropy_with_logits"""

parameter_initializer = initializer()

def CostFunction(z3, y):
    logits = tf.transpose(z3)
    labels = tf.transpose(y.astype('float32'))
    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))
    return cost

def gradient(inputs, targets, parameters):
    with tf.GradientTape() as tape:
        z3 = forwardPass(inputs, targets, parameters)
        # control the cost function
        loss_value = CostFunction(z3, targets) # 2st
        
    return [tape.gradient(loss_value, list(parameters.values())), loss_value]

# run 18 mins
optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001)

for epoch in range(100):
    minibatches = random_mini_batches(X_osa.T, y_osa, 32, seed = 1)
    
    for minibatch in minibatches:
        x = minibatch[0].astype(np.float32)
        y = minibatch[1].astype(np.float32)
        
        grads, loss_value = gradient(x, y, parameter_initializer)
        optimizer.apply_gradients(zip(grads, list(parameter_initializer.values())))

EvaluatePerformance(X_osa, y_osa, X_val, y_val, parameter_initializer)

"""## V. Summary"""

Model = ["Logistic Regression", "Naive Bayes", 'SVM', 'Artificial Neural Networks']
F1 = [0.56, 0.82, 0.8, 0.57]
Recall1 = [0.84, 0.74, 0.79, 0.9]
Precision = [0.43, 0.91, 0.81, 0.42]
MC = pd.DataFrame({'Model' : Model, 'F1 score': F1, 'Sensitivity (Recall) Macro Avg': Recall1, 'Precision':Precision})
MC

n_groups = 4
fig, ax = plt.subplots(figsize = (12, 8))
index = np.arange(n_groups)
bar_width = 0.25
opacity = 0.4

r1 = plt.bar(index, F1, bar_width,alpha=opacity,label='F1')

r2 = plt.bar(index + bar_width, Recall1, bar_width,alpha=opacity,label='Recall')

r3 = plt.bar(index + 2*bar_width, Precision, bar_width,alpha=opacity,label='Precision')

plt.xlabel('Model', fontsize = 13)
plt.ylabel('Value', fontsize = 13)
plt.title('Model Classification Ability Comparison ', fontsize = 16)
plt.xticks(index + bar_width, ("Logistic Regression", "Naive Bayes", 'SVM', 'Artificial Neural Networks'))
plt.legend()

#plt.tight_layout()
plt.show()



